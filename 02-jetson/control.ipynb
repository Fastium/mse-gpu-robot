{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160b09dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetcam.csi_camera import CSICamera\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import ipywidgets.widgets as widgets\n",
    "import onnxruntime as ort\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import time\n",
    "from jetracer.nvidia_racecar import NvidiaRacecar\n",
    "\n",
    "# Configuration\n",
    "dataset_dir = \"dataset_capture_3\"\n",
    "capture_interval_sec = 5\n",
    "\n",
    "# Create directory if it doesn't exist (good I/O practice)\n",
    "if not os.path.exists(dataset_dir):\n",
    "    os.makedirs(dataset_dir)\n",
    "\n",
    "counter = 0\n",
    "\n",
    "car = NvidiaRacecar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca77df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "MODEL_PATH = \"models/resnet18_15.onnx\" \n",
    "NUM_CLASSES = 2\n",
    "\n",
    "# Priority on TensorRT but CUDA as fallback\n",
    "providers = [\n",
    "    ('TensorrtExecutionProvider', {\n",
    "        'device_id': 0,\n",
    "        'trt_max_workspace_size': 2147483648, # 2GB workspace\n",
    "        'trt_fp16_enable': True, # Activate FP16\n",
    "    }),\n",
    "    ('CUDAExecutionProvider', {\n",
    "        'device_id': 0,\n",
    "    })\n",
    "]\n",
    "print(f\"Loading model {MODEL_PATH} with providers : {providers}\")\n",
    "\n",
    "# Create session\n",
    "ort_sess = ort.InferenceSession(MODEL_PATH, providers=providers)\n",
    "print(\"Session ONNX loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1c8bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_transform(resolution=(224,224)):\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize(resolution),\n",
    "        transforms.CenterCrop(resolution),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "transform = default_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25d9775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(image, session, transform):\n",
    "    # 1. Loading and preprocessing\n",
    "    \n",
    "    # Transformation et send to GPU\n",
    "    input_tensor = transform(image).unsqueeze(0).to(\"cuda:0\")\n",
    "\n",
    "    # 2. IO Binding\n",
    "    io_binding = session.io_binding()\n",
    "\n",
    "    # Bind Input\n",
    "    io_binding.bind_input(\n",
    "        name=\"input_0\", # !!!! Vérifie bien que c'est le nom dans ton ONNX (netron.app pour vérifier)\n",
    "        device_type=\"cuda\",\n",
    "        device_id=0,\n",
    "        element_type=np.float32,\n",
    "        shape=tuple(input_tensor.shape),\n",
    "        buffer_ptr=input_tensor.data_ptr()\n",
    "    )\n",
    "\n",
    "    # Prepare Tensor Output\n",
    "    output_tensor = torch.empty((1, NUM_CLASSES), dtype=torch.float32, device=\"cuda:0\").contiguous()\n",
    "\n",
    "    # Bind Output\n",
    "    io_binding.bind_output(\n",
    "        name=\"output_0\", # !!! Idem, vérifie le nom\n",
    "        device_type=\"cuda\",\n",
    "        device_id=0,\n",
    "        element_type=np.float32,\n",
    "        shape=tuple(output_tensor.shape),\n",
    "        buffer_ptr=output_tensor.data_ptr()\n",
    "    )\n",
    "\n",
    "    # 3. Execution and time measure\n",
    "    start = time.time()\n",
    "    session.run_with_iobinding(io_binding)\n",
    "    end = time.time()\n",
    "    \n",
    "    latency_ms = (end - start) * 1000\n",
    "\n",
    "    # 4. Get result\n",
    "    probas = output_tensor.to(\"cpu\")[0].tolist()\n",
    "    \n",
    "    return probas, latency_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d9b5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciation camera\n",
    "camera = CSICamera(\n",
    "    width=224, height=224, # 224x224\n",
    "    capture_width=1080, # 1080\n",
    "    capture_height=720, # 720\n",
    "    capture_fps=30 # 30\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 1. Start the stream ONLY ONCE\n",
    "# Checking running state prevents heavy re-initialization overhead\n",
    "if not camera.running:\n",
    "    camera.running = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb1af78",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    while True:\n",
    "        # Get current image from memory (Zero latency here)\n",
    "        # camera.value is a reference to the latest frame in RAM\n",
    "        image = camera.value\n",
    "        \n",
    "        if image is not None:\n",
    "                probas, latency = run_inference(image, ort_sess, transform)\n",
    "                classe_predite = np.argmax(probas)\n",
    "                label = \"CIBLE\" if classe_predite == 0 else \"NO CIBLE\"\n",
    "                print(f\"Prediction : {label}\")\n",
    "                if label == \"CIBLE\" : \n",
    "                     car.throttle = 0.3\n",
    "                else :\n",
    "                     car.throttle = 0\n",
    "\n",
    "        else:\n",
    "            print(\"Error: No image retrieved from stream.\")\n",
    "\n",
    "        # Efficient sleep to release CPU for other tasks\n",
    "        time.sleep(capture_interval_sec)\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    # This block handles the Jupyter 'Stop' button event\n",
    "    print(\"\\nCapture stopped by user.\")\n",
    "    \n",
    "finally:\n",
    "\n",
    "    camera.running = False \n",
    "    print(\"Camera stopped. Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7316361b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
